{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d8b1ed2-718e-44db-a410-d6a03b16270d",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon;\">Imports</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541f8a4d-06da-4e2f-bf4e-f26b164ce10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82e4967-bb07-4f5e-aec9-909bcaabda9e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon;\">Visual aids</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635d0dc3-0b82-4efb-8acc-d4cf7119d974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colors:\n",
    "    RED = '\\033[91m' + '\\033[1m' + '\\033[4m'\n",
    "    GREEN = '\\033[92m' + '\\033[1m' + '\\033[4m'\n",
    "    YELLOW = '\\033[93m' + '\\033[1m' + '\\033[4m'\n",
    "    BLUE = '\\033[94m' + '\\033[1m' + '\\033[4m'\n",
    "    END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec1ff89-27a3-469a-b80d-619c64be6a41",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon;\">A. Initial exploration</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e49c8c8-5448-407b-ba58-c653da2cd38c",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">1. Import data</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a75ea43-aa4b-48e1-97c5-a997da6a94df",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(\"Youtube01-Psy.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b342e8ad-cf76-41b5-8dcf-2ca95c376ec8",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">2. Examination of properties of raw data frame</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa522ff-f714-47e7-98bb-c1057e317ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + \"Shape of data frame:\" + Colors.END)\n",
    "print(raw_data.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Data frame fields:\" + Colors.END)\n",
    "print(raw_data.columns)\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Data frame info:\" + Colors.END)\n",
    "raw_data.info()\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Unique entries per attribute:\" + Colors.END)\n",
    "print(raw_data.nunique())\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Data frame head:\" + Colors.END)\n",
    "raw_data.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a036efa2-963b-44f8-bdaf-2eab17d46250",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">3. Analysis of raw data frame</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30a4bde-a884-4ea1-b2d7-f8d7f2b123d7",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(120,120,200,0.25); padding: 10px;\">\n",
    "    <h5>Analysis of raw data frame<br></h5>\n",
    "        <body>\n",
    "            Main observations:\n",
    "            <ol>\n",
    "                <li>The data set contains 350 entries and 5 attributes.</li>\n",
    "                <li>None of the fields in the data set are empty.</li>\n",
    "                <li>Fields,<b>COMMENT_ID, AUTHOR, DATE</b> contain mostly unique values, hence they will be ignored in classifying the <b>CONTENT</b> class.</li>\n",
    "            </ol>\n",
    "    </body>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65f822f-5303-4ce3-88e2-b1d029c793a5",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">4. Summary examination of <b>CONTENT</b> field.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e1d1a7-e701-46b6-b60b-426e293eebb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max length of CONTENT field\n",
    "max_length_comment = raw_data[\"CONTENT\"].str.len().max()\n",
    "print(Colors.BLUE + \"Max length of content:\" + Colors.END)\n",
    "print(max_length_comment)\n",
    "print(\"\")\n",
    "\n",
    "# Min length of CONTENT field\n",
    "min_length_comment = raw_data[\"CONTENT\"].str.len().min()\n",
    "print(Colors.BLUE + \"Min length of content:\" + Colors.END)\n",
    "print(min_length_comment)\n",
    "print(\"\")\n",
    "\n",
    "# Max length of spam comment\n",
    "max_length_comment_spam = raw_data.loc[raw_data[\"CLASS\"] == 1, \"CONTENT\"].str.len().max()\n",
    "print(Colors.BLUE + \"Max length of spam content:\" + Colors.END)\n",
    "print(max_length_comment_spam)\n",
    "print(\"\")\n",
    "\n",
    "# Min length of spam comment\n",
    "max_length_comment_ham = raw_data.loc[raw_data[\"CLASS\"] == 0, \"CONTENT\"].str.len().max()\n",
    "print(Colors.BLUE + \"Max length of ham content:\" + Colors.END)\n",
    "print(max_length_comment_ham)\n",
    "print(\"\")\n",
    "\n",
    "# Max length of ham comment\n",
    "min_length_comment_spam = raw_data.loc[raw_data[\"CLASS\"] == 1, \"CONTENT\"].str.len().min()\n",
    "print(Colors.BLUE + \"Min length of spam content:\" + Colors.END)\n",
    "print(min_length_comment_spam)\n",
    "print(\"\")\n",
    "\n",
    "# Min legnth of ham comment\n",
    "min_length_comment_ham = raw_data.loc[raw_data[\"CLASS\"] == 0, \"CONTENT\"].str.len().min()\n",
    "print(Colors.BLUE + \"Min length of ham content:\" + Colors.END)\n",
    "print(min_length_comment_ham)\n",
    "print(\"\")\n",
    "\n",
    "# Print longest spam comment\n",
    "filtered_data_class = raw_data[raw_data[\"CLASS\"] == 1]\n",
    "longest_content_class = filtered_data_class.loc[filtered_data_class[\"CONTENT\"].str.len().idxmax(), \"CONTENT\"]\n",
    "print(Colors.BLUE + \"Longest spam comment:\" + Colors.END)\n",
    "print(longest_content_class)\n",
    "print(\"\")\n",
    "\n",
    "# Print shortest spam comment\n",
    "filtered_data_class = raw_data[raw_data[\"CLASS\"] == 1]\n",
    "shortest_content_class = filtered_data_class.loc[filtered_data_class[\"CONTENT\"].str.len().idxmin(), \"CONTENT\"]\n",
    "print(Colors.BLUE + \"Shortest spam comment:\" + Colors.END)\n",
    "print(shortest_content_class)\n",
    "print(\"\")\n",
    "\n",
    "# Print longest hamm comment\n",
    "filtered_data_class = raw_data[raw_data[\"CLASS\"] == 0]\n",
    "longest_content_class = filtered_data_class.loc[filtered_data_class[\"CONTENT\"].str.len().idxmax(), \"CONTENT\"]\n",
    "print(Colors.BLUE + \"Longest ham comment:\" + Colors.END)\n",
    "print(longest_content_class)\n",
    "print(\"\")\n",
    "\n",
    "filtered_data_class = raw_data[raw_data[\"CLASS\"] == 0]\n",
    "shortest_content_class = filtered_data_class.loc[filtered_data_class[\"CONTENT\"].str.len().idxmin(), \"CONTENT\"]\n",
    "print(Colors.BLUE + \"Shortest ham comment:\" + Colors.END)\n",
    "print(shortest_content_class)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e423ac8-c565-4007-9646-a79d078587e0",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">5. Visual examination of <b>CONTENT</b> field.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb49eb45-dd53-41fb-87b9-50d728811fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get lengths of all spam and ham comments\n",
    "spam_lengths = raw_data.loc[raw_data[\"CLASS\"]==1, \"CONTENT\"].str.len()\n",
    "ham_lengths = raw_data.loc[raw_data[\"CLASS\"]==0, \"CONTENT\"].str.len()\n",
    "\n",
    "# Plot distribution of spam and ham lengths\n",
    "fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(10,10))\n",
    "\n",
    "ax[0].hist(spam_lengths, bins=30, color=\"red\", edgecolor=\"red\", alpha=0.5)\n",
    "ax[0].set_title(\"Distribution of spam comment lengths\")\n",
    "ax[0].set_xlabel(\"Length\")\n",
    "ax[0].set_ylabel(\"Counts\")\n",
    "\n",
    "ax[1].hist(ham_lengths, bins=30, color=\"green\", edgecolor=\"green\", alpha=0.5)\n",
    "ax[1].set_title(\"Distribution of ham comment lengths\")\n",
    "ax[1].set_xlabel(\"Length\")\n",
    "ax[1].set_ylabel(\"Counts\")\n",
    "\n",
    "ax[2].bar( x=1, height=(raw_data[\"CLASS\"]==1).sum(), width =0.5, color='red', edgecolor=\"red\", alpha=0.6, label=\"Spam\")\n",
    "ax[2].bar( x=2, height=(raw_data[\"CLASS\"]==0).sum(), width =0.5, color='green', edgecolor=\"green\", alpha=0.6, label=\"Ham\")\n",
    "ax[2].set_xticks([1, 2])\n",
    "ax[2].set_xticklabels(['Spam', 'Ham'])\n",
    "ax[2].set_title(\"Number of spam vs ham comments\")\n",
    "ax[2].set_xlabel(\"Categories\")\n",
    "ax[2].set_ylabel(\"Counts\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a613179b-6660-47e9-8230-51d4d5b20d7d",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">6. Analysis of <b>CONTENT</b> field.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38025e87-e49a-4702-b3b1-18cd3dd85ea6",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(120,120,200,0.25); padding: 10px;\">\n",
    "    <h5>Analysis of CONTENT<br></h5>\n",
    "        <body>\n",
    "            <ul>\n",
    "                <li>\n",
    "                    Based on a summary statistical analysis there aren't many features that distinguish between spam and ham comments.\n",
    "                </li>\n",
    "                <li>\n",
    "                    Both spam and ham comments show similarly skewed distribution, with most of them having total character counts bounded between 0 - 200 characters. \n",
    "                </li>\n",
    "                <li>\n",
    "                    The longest spam message has more characters than the longest ham message, however, the statistical relevance of this is undecided.\n",
    "                </li>\n",
    "                <li>\n",
    "                    It is not immediately clear if including content length as a feature will improve the performance of a classifier.\n",
    "                </li>\n",
    "                <li>\n",
    "                    The data set is balanced with roughly the same number of spam and ham examples.\n",
    "                </li>\n",
    "            </ul>\n",
    "    </body>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4516303-1c1b-48cd-a03d-cef481e8f161",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon;\">B. Data preparation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f01fe8-5fc1-4b37-9269-d9259b5f245e",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">1. Prepare new dataframe with only <b>CONTENT</b> and <b>CLASS</b> fields.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68ea3b3-b97b-41d8-913d-12756b8545b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe with appropriate fields\n",
    "proc_data = raw_data[[\"CLASS\",\"CONTENT\"]].copy() # Use copy to supress slice warning (we want a copy not a slice referencing the memory location of raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a455a32-6cc2-4949-b331-f9aa10074aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the dataframe\n",
    "print(Colors.BLUE + \"Shape of data frame:\" + Colors.END)\n",
    "print(proc_data.shape)\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Data frame fields:\" + Colors.END)\n",
    "print(proc_data.columns)\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Data frame info:\" + Colors.END)\n",
    "proc_data.info()\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Unique entries per attribute:\" + Colors.END)\n",
    "print(proc_data.nunique())\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Data frame head:\" + Colors.END)\n",
    "proc_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495528ea-b536-42a3-9c6b-d907f954e0c2",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">2. Convert text to lowercase.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322ba6a-103f-48c0-9c1b-089c78b02539",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data[\"PROC_CONTENT\"] = proc_data[\"CONTENT\"].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecc3d75-281e-45bf-97a6-9b098a0b0018",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + \"Data frame head:\" + Colors.END)\n",
    "proc_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d11ff19-43a9-4835-a6e6-20589b564dec",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">3. Tokenize words.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f21a65d-75a7-4935-bf1f-3d3c0471aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data[\"PROC_CONTENT\"] = proc_data[\"PROC_CONTENT\"].apply(lambda x: WordPunctTokenizer().tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b25aec0-aece-42b5-a840-1758fdf51b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + \"Data frame head:\" + Colors.END)\n",
    "proc_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fee9aac-9c58-473c-bc49-6550cfc80c18",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">4. Remove stop words.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5683a11-d398-4523-a6b3-301b06df6643",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(tokens):\n",
    "    return [word for word in tokens if word not in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727b7fef-6819-4e20-9cbc-1c6ac96ca797",
   "metadata": {},
   "outputs": [],
   "source": [
    "proc_data[\"PROC_CONTENT\"] = proc_data[\"PROC_CONTENT\"].apply(remove_stopwords)\n",
    "print(Colors.BLUE + \"Data frame head:\" + Colors.END)\n",
    "proc_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f759852-ba29-4111-b564-4414d023a4ee",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">5. Remove non-alpha numeric characters.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01191e3e-41c5-4cd4-9002-23e10611c27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punct(tokens):\n",
    "    return [word for word in tokens if word.isalnum()]\n",
    "\n",
    "proc_data[\"PROC_CONTENT\"] = proc_data[\"PROC_CONTENT\"].apply(remove_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208553cc-934f-41db-8a11-c3553431fdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + \"Data frame head:\" + Colors.END)\n",
    "proc_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dad209-3b8f-4893-b619-294e52715f69",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">6. Lemmatize words.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f66a8f9-6cad-4449-91df-ad57d20c10d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_words(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "proc_data[\"PROC_CONTENT\"] = proc_data[\"PROC_CONTENT\"].apply(lemmatize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f74bdf-381e-4a59-bb11-aabfa5294fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + \"Data frame head:\" + Colors.END)\n",
    "proc_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb6333-156e-4fdd-9ba3-42fe3a94c63d",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">7. Re-assemble string post processing.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871aeb30-b3d3-4570-8dbc-84cc48d19479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_words(tokens):\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "proc_data[\"PROC_CONTENT\"] = proc_data[\"PROC_CONTENT\"].apply(join_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e1aeee-5f3f-4fd7-8304-0a35a3e0ec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + \"Data frame head:\" + Colors.END)\n",
    "proc_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5f749b-d765-44e8-924f-2c63e5acc229",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon;\">C. Data transformation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0914bdff-232c-4c87-8596-a49eee889d05",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">1. Vectorize string with count vectorizer.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1af73a-363a-4600-a89b-bd5e31c1eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "bow_sparse_matrix = vectorizer.fit_transform(proc_data['PROC_CONTENT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ae4726-28a4-421c-9486-9314d34d01d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + \"Type of object returned by CountVectorizer().fit_transform:\" + Colors.END)\n",
    "print(type(bow_sparse_matrix))\n",
    "\n",
    "print(Colors.BLUE + \"Shape of sparse matrix returned by CountVectorizer().fit_transform:\" + Colors.END)\n",
    "print(bow_sparse_matrix.shape)\n",
    "\n",
    "print(Colors.BLUE + \"Density of sparse matrix returned by CountVectorizer().fit_transform:\" + Colors.END)\n",
    "print( bow_sparse_matrix.nnz / (bow_sparse_matrix.shape[0]*bow_sparse_matrix.shape[1]) )\n",
    "\n",
    "print(Colors.BLUE + \"Sum sparse matrix returned by CountVectorizer().fit_transform:\" + Colors.END)\n",
    "print( bow_sparse_matrix.toarray().sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5fe0f8-500b-45f7-9f2c-ffeadf86aceb",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">2. Downscaling with TF-IDF.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9d8f0c-2d67-49a1-b1db-aa9e368f281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_sparse_matrix = tfidf_transformer.fit_transform(bow_sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b783a563-d1a6-484d-b007-922e5e23ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + \"Type of object returned by TfidTransformer().fit_transform:\" + Colors.END)\n",
    "print(type(tfidf_sparse_matrix))\n",
    "\n",
    "print(Colors.BLUE + \"Shape of sparse matrix returned by TfidTransformer().fit_transform:\" + Colors.END)\n",
    "print(tfidf_sparse_matrix.shape)\n",
    "\n",
    "print(Colors.BLUE + \"Density of sparse matrix returned by TfidTransformer().fit_transform:\" + Colors.END)\n",
    "print( tfidf_sparse_matrix.nnz / (tfidf_sparse_matrix.shape[0]*tfidf_sparse_matrix.shape[1]) )\n",
    "\n",
    "print(Colors.BLUE + \"Sum sparse matrix returned by TfidTransformer().fit_transform:\" + Colors.END)\n",
    "print( tfidf_sparse_matrix.toarray().sum() )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a0d501-1dbe-411a-86d5-c4098deee426",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">3. Create the feature matrix.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b5f091-5b93-4761-978c-89ba4156bb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names_out();\n",
    "tfidf_df = pd.DataFrame(tfidf_sparse_matrix.toarray(), columns=feature_names)\n",
    "feat_mat = pd.concat([proc_data[\"CLASS\"],tfidf_df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1041237-1613-4ce9-a2c0-c28f30f761ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + \"Shape of feature matrix:\" + Colors.END)\n",
    "print( feat_mat.shape )\n",
    "\n",
    "print(Colors.BLUE + \"Head of feature matrix:\" + Colors.END)\n",
    "print( feat_mat.head(3) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cf6e2b-9fbb-4347-8788-09e791ac6230",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">4. Shuffle the data.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed87bba-64de-4fff-88c1-677d7f0df7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_feat_mat = feat_mat.sample(frac=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfeb990-0e09-478e-b371-b44b56f25be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + \"Shape of shuffled feature matrix:\" + Colors.END)\n",
    "print( shuffled_feat_mat.shape )\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Head of shuffled feature matrix:\" + Colors.END)\n",
    "print( shuffled_feat_mat.head(3) )\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4f3c65-9188-4762-9f33-fd66c7e40455",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">5. Analysis.</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b933a31-1771-45c7-990a-4390cb4dda41",
   "metadata": {},
   "source": [
    "<div style=\"background-color: rgba(120,120,200,0.25); padding: 10px;\">\n",
    "    <h5>Analysis of BOW vs TF-IDF transforms<br></h5>\n",
    "    <body>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <th>S No</th> <th>Matrix</th> <th>Rows</th> <th>Columns</th> <th>Sum of elements</th> <th>Density</th>\n",
    "            </tr>\n",
    "            <tr>\n",
    "                <td>1</td> <td>Original</td> <td>350</td> <td>2</td> <td>Not specified</td> <td>1</td>\n",
    "            </tr>\n",
    "                <td>2</td> <td>Count vectorizer sparse</td> <td>350</td> <td>1229</td> <td>3152</td> <td>0.0065</td>\n",
    "            <tr>\n",
    "            <tr>\n",
    "                <td>3</td> <td>TF-IDF sparse</td> <td>350</td> <td>1229</td> <td>881.132</td> <td>0.0065</td>\n",
    "            </tr>\n",
    "        </table> \n",
    "        We observe that:\n",
    "        <ul>\n",
    "            <li>When the data is vectorized, the number of columns increases to the number of unique words in the corpus.</li>\n",
    "            <li>The density of sparse matrices are low, i.e. most of the matrix elements are 0.</li>\n",
    "            <li>As expected, the sparse matrices from Count Vectorizer and TF-IDF have the same number of columns and the same density.</li>\n",
    "            <li>The sum of all the elements in the sparse matrix corresponding to TF-IDF is lower than the sum of all the elements in the sparse matrix of Count Vectorizer. This is because TF-IDF downscales the values.</li>\n",
    "        </ul>\n",
    "    </body>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d36d91-63f7-4d32-8a5e-bbbdd0b7fbb4",
   "metadata": {},
   "source": [
    "<h3 style=\"color:maroon;\">D. Model building</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fe5870-cc94-438d-84b5-290b52e79407",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">1. Make a 75-25 train test split without using train_test_split.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57fd24-e0a9-4fae-84f8-e3aabef8677c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine indices\n",
    "split_index = int( 0.75 * len(shuffled_feat_mat) )\n",
    "\n",
    "# Allocate data according to indices\n",
    "train_data = shuffled_feat_mat[:split_index]\n",
    "test_data = shuffled_feat_mat[split_index:]\n",
    "\n",
    "# Separate classes from features for each data set\n",
    "x_train = train_data.drop(columns = [\"CLASS\"])\n",
    "y_train = train_data[\"CLASS\"]\n",
    "\n",
    "x_test = test_data.drop(columns = [\"CLASS\"])\n",
    "y_test = test_data[\"CLASS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a4c18c7-1bfd-4523-9ac8-0c5b1b7eb651",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + \"Split index:\" + Colors.END)\n",
    "print( split_index )\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Shape of x_train:\" + Colors.END)\n",
    "print( x_train.shape )\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Shape of y_train:\" + Colors.END)\n",
    "print( y_train.shape )\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Shape of x_test:\" + Colors.END)\n",
    "print( x_test.shape )\n",
    "print(\"\")\n",
    "\n",
    "print(Colors.BLUE + \"Shape of y_test:\" + Colors.END)\n",
    "print( y_test.shape )\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359b8755-d534-4847-af6f-4b5f86a47c82",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">2. Fit multinomial Naive-Bayes.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0167ab5-3909-47b7-b942-145977e20ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59499b09-4262-42c1-9666-304e73b28aed",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">3. Cross validation.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ac73f-5dc6-4eb3-b60c-d4854d199dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_scores = cross_val_score(clf, x_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04307d3-cb0b-4af4-bf8b-c10fbdac7183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the cross-validation sc0ores\n",
    "print(Colors.BLUE + \"Cross-validation scores:\" + Colors.END, cross_val_scores)\n",
    "print(Colors.BLUE + \"Mean accuracy:\" + Colors.END, cross_val_scores.mean())\n",
    "print(Colors.BLUE + \"Standard deviation:\" + Colors.END, cross_val_scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de56a4b0-0c92-4f78-acb1-45b6e82c0442",
   "metadata": {},
   "source": [
    "<h4 style=\"color:#874c62;\">4. Test model, print accuracy and confusion matrix.</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca27f3-0c33-4d7c-ad30-e74466ab8240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a62605-d0f2-4331-b6dc-b5aae20e9888",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Colors.BLUE + 'Accuracy: ' + Colors.END, accuracy)\n",
    "\n",
    "# Display classification report\n",
    "print(Colors.BLUE + \"Classification Report:\" + Colors.END)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7912fcaa-8dd4-4970-bf3c-62db125cd059",
   "metadata": {},
   "source": [
    "<h3 style=\"color:white; background-color:#000000\">Consolidating above code into pipelines</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37b18044-297a-44dc-9771-e2f42688903b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text processing pipeline\n",
    "def process_text (text):\n",
    "    '''Process text for vectorization'''\n",
    "    \n",
    "    # Set up\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Process\n",
    "    text = text.lower()\n",
    "    text = WordPunctTokenizer().tokenize(text)\n",
    "    text = [word for word in text if word.isalnum()]\n",
    "    text = [word for word in text if word not in stop_words]\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Return processed text\n",
    "    return text\n",
    "\n",
    "# Vectorization pipeline\n",
    "def vectorize (dataframe, text_field, label_field, training_data=0):\n",
    "    '''Vectorize text for Naive-Bayes classification'''\n",
    "\n",
    "    # Set up\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    tfidf_transformer = TfidfTransformer()\n",
    "    \n",
    "    # Vectorize\n",
    "    bow_sparse_matrix = count_vectorizer.fit_transform(dataframe[text_field])\n",
    "    tfidf_sparse_matrix = tfidf_transformer.fit_transform(bow_sparse_matrix)\n",
    "\n",
    "    # Create feature matrix\n",
    "    feature_names = count_vectorizer.get_feature_names_out();\n",
    "    tfidf_df = pd.DataFrame(tfidf_sparse_matrix.toarray(), columns=feature_names)\n",
    "    # Re-add classification labels is data is being vectorized for training-testing\n",
    "    if (training_data == 1):\n",
    "        feat_mat = pd.concat([dataframe[label_field],tfidf_df], axis = 1)\n",
    "    # Don't add classification label if predicting new data\n",
    "    else:\n",
    "        feat_mat = tfidf_df\n",
    "\n",
    "    # Return feature matrix\n",
    "    return feat_mat\n",
    "\n",
    "# Model pipeline\n",
    "def model (feat_mat, text_field, label_field, split_ratio=0.75):\n",
    "    '''Build and train model'''\n",
    "\n",
    "    # Set up\n",
    "    clf = MultinomialNB()\n",
    "    \n",
    "    # Shuffle matrix\n",
    "    shuffled_feat_mat = feat_mat.sample(frac=1, random_state=1)\n",
    "    # Split data into test and train sets\n",
    "    split_index = int( 0.75 * len(shuffled_feat_mat) )\n",
    "    train_data = shuffled_feat_mat[:split_index]\n",
    "    test_data = shuffled_feat_mat[split_index:]\n",
    "    x_train = train_data.drop(columns = [\"CLASS\"])\n",
    "    y_train = train_data[\"CLASS\"]\n",
    "    x_test = test_data.drop(columns = [\"CLASS\"])\n",
    "    y_test = test_data[\"CLASS\"]\n",
    "    # Train model\n",
    "    trained_model = clf.fit(x_train, y_train)\n",
    "    # Test model\n",
    "    y_pred = clf.predict(x_test)\n",
    "    # Print classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Return model\n",
    "    return trained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff10f3-9b4f-4f55-b70c-b42ac398df6e",
   "metadata": {},
   "source": [
    "<h3 style=\"color:white; background-color:#000000\">Testing pipeline</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9dc939b-c30d-492b-b0f5-1a94bf2c57b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        42\n",
      "           1       0.98      0.93      0.96        46\n",
      "\n",
      "    accuracy                           0.95        88\n",
      "   macro avg       0.95      0.96      0.95        88\n",
      "weighted avg       0.96      0.95      0.95        88\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 26\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# print(feat_mat.head(3))\u001b[39;00m\n\u001b[1;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m model(feat_mat,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCONTENT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCLASS\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m model\u001b[38;5;241m.\u001b[39mpredict(\u001b[43mx_test\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "raw_data = pd.read_csv(\"Youtube01-Psy.csv\")\n",
    "\n",
    "proc_data = raw_data[[\"CLASS\",\"CONTENT\"]].copy()\n",
    "# print(proc_data.head(3))\n",
    "\n",
    "proc_data[\"CONTENT\"] = proc_data[\"CONTENT\"].apply(process_text)\n",
    "# print(proc_data.head(3))\n",
    "\n",
    "feat_mat=vectorize(proc_data, \"CONTENT\", \"CLASS\",1)\n",
    "# print(feat_mat.head(3))\n",
    "\n",
    "model = model(feat_mat,\"CONTENT\",\"CLASS\")\n",
    "\n",
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a863110-39f3-4990-a6c0-0a3ccd2b969d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
